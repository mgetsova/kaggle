{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6a3766",
   "metadata": {
    "papermill": {
     "duration": 0.008251,
     "end_time": "2023-02-23T09:15:28.249156",
     "exception": false,
     "start_time": "2023-02-23T09:15:28.240905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This notebook is an exercise in the [Intro to Game AI and Reinforcement Learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/one-step-lookahead).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5960e0",
   "metadata": {
    "papermill": {
     "duration": 0.00415,
     "end_time": "2023-02-23T09:15:28.258375",
     "exception": false,
     "start_time": "2023-02-23T09:15:28.254225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In the tutorial, you learned how to define a simple heuristic that the agent used to select moves.  In this exercise, you'll check your understanding and make the heuristic more complex.\n",
    "\n",
    "To get started, run the code cell below to set up our feedback system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa4bae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:28.269596Z",
     "iopub.status.busy": "2023-02-23T09:15:28.268967Z",
     "iopub.status.idle": "2023-02-23T09:15:28.431396Z",
     "shell.execute_reply": "2023-02-23T09:15:28.430098Z"
    },
    "papermill": {
     "duration": 0.171628,
     "end_time": "2023-02-23T09:15:28.434379",
     "exception": false,
     "start_time": "2023-02-23T09:15:28.262751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment lux_ai_s2 failed: No module named 'vec_noise'\n"
     ]
    }
   ],
   "source": [
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.game_ai.ex2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ab813",
   "metadata": {
    "papermill": {
     "duration": 0.004079,
     "end_time": "2023-02-23T09:15:28.443652",
     "exception": false,
     "start_time": "2023-02-23T09:15:28.439573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1) A more complex heuristic\n",
    "\n",
    "The heuristic from the tutorial looks at all groups of four adjacent grid locations on the same row, column, or diagonal and assigns points for each occurrence of the following patterns:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/vzQa4ML.png\" width=60%><br/>\n",
    "</center>\n",
    "\n",
    "In the image above, we assume that the agent is the red player, and the opponent plays yellow discs.\n",
    "\n",
    "For reference, here is the `get_heuristic()` function from the tutorial:\n",
    "```python\n",
    "def get_heuristic(grid, mark, config):\n",
    "    num_threes = count_windows(grid, 3, mark, config)\n",
    "    num_fours = count_windows(grid, 4, mark, config)\n",
    "    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "    score = num_threes - 1e2*num_threes_opp + 1e6*num_fours\n",
    "    return score\n",
    "```\n",
    "\n",
    "In the `get_heuristic()` function, `num_fours`, `num_threes`, and `num_threes_opp` are the number of windows in the game grid that are assigned 1000000, 1, and -100 point(s), respectively. \n",
    "    \n",
    "In this tutorial, you'll change the heuristic to the following (where you decide the number of points to apply in each of `A`, `B`, `C`, `D`, and `E`).  You will define these values in the code cell below.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/FBoWr2f.png\" width=80%><br/>\n",
    "</center>\n",
    "    \n",
    "\n",
    "To check your answer, we use your values to create a heuristic function as follows:\n",
    "\n",
    "```python\n",
    "def get_heuristic_q1(grid, col, mark, config):\n",
    "    num_twos = count_windows(grid, 2, mark, config)\n",
    "    num_threes = count_windows(grid, 3, mark, config)\n",
    "    num_fours = count_windows(grid, 4, mark, config)\n",
    "    num_twos_opp = count_windows(grid, 2, mark%2+1, config)\n",
    "    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "    score = A*num_fours + B*num_threes + C*num_twos + D*num_twos_opp + E*num_threes_opp\n",
    "    return score\n",
    "```\n",
    "\n",
    "This heuristic is then used to create an agent, that competes against the agent from the tutorial in 50 different game rounds.  In order to be marked correct, \n",
    "- your agent must win at least half of the games, and\n",
    "- `C` and `D` must both be nonzero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5016b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:28.454421Z",
     "iopub.status.busy": "2023-02-23T09:15:28.453761Z",
     "iopub.status.idle": "2023-02-23T09:15:46.607313Z",
     "shell.execute_reply": "2023-02-23T09:15:46.605698Z"
    },
    "papermill": {
     "duration": 18.161841,
     "end_time": "2023-02-23T09:15:46.609766",
     "exception": false,
     "start_time": "2023-02-23T09:15:28.447925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Agent's Win Percentage (in 50 game rounds): 0.86\n",
      "Tutorial Agent's Win Percentage (in 50 game rounds): 0.14\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_BetterHeuristic\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Assign your values here\n",
    "A = 1000000\n",
    "B = 100\n",
    "C = 1\n",
    "D = -10\n",
    "E = -1000\n",
    "# Check your answer (this will take a few seconds to run!)\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b10745d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.621718Z",
     "iopub.status.busy": "2023-02-23T09:15:46.621257Z",
     "iopub.status.idle": "2023-02-23T09:15:46.626672Z",
     "shell.execute_reply": "2023-02-23T09:15:46.625571Z"
    },
    "papermill": {
     "duration": 0.014236,
     "end_time": "2023-02-23T09:15:46.629009",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.614773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#q_1.hint()\n",
    "#q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fd660",
   "metadata": {
    "papermill": {
     "duration": 0.00434,
     "end_time": "2023-02-23T09:15:46.638156",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.633816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2) Does the agent win?\n",
    "\n",
    "Consider the game board below.  \n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/AlnaQ3J.png\" width=30%><br/>\n",
    "</center>\n",
    "\n",
    "Say the agent uses red discs, and it's the agent's turn.  \n",
    "- If the agent uses the heuristic **_from the tutorial_**, does it win or lose the game?\n",
    "- If the agent uses the heuristic **_that you just implemented_**, does it win or lose the game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ed08db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.649175Z",
     "iopub.status.busy": "2023-02-23T09:15:46.648736Z",
     "iopub.status.idle": "2023-02-23T09:15:46.657508Z",
     "shell.execute_reply": "2023-02-23T09:15:46.656211Z"
    },
    "papermill": {
     "duration": 0.017076,
     "end_time": "2023-02-23T09:15:46.659846",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.642770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom tutorial heuristic, a red dot in the left column yeilds a score of 0 as does a red dot in the right column so the agent is equally \\nlikely to choose either.\\n\\nFrom our heuristic above, left column yeilds a score of 0 but the right column yeilds a score of 1 so the agent will pick the right column.\\nBut if a red dot is dropped in the right column, the yellow player has a guranteed win in the next turn whereas if a red dot were dropped \\nin the left column, the yellow player would have been forced to drop a yellow piece in the right column on the next turn, guranteeing red a \\nwin thereafter. Thus, while our heuristic generally performs well, in this case it would lose the game whereas the more poorly defined\\nheuristic from the tutorial would still give the red player a 50% chance of winning. \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "From tutorial heuristic, a red dot in the left column yeilds a score of 0 as does a red dot in the right column so the agent is equally \n",
    "likely to choose either.\n",
    "\n",
    "From our heuristic above, left column yeilds a score of 0 but the right column yeilds a score of 1 so the agent will pick the right column.\n",
    "But if a red dot is dropped in the right column, the yellow player has a guranteed win in the next turn whereas if a red dot were dropped \n",
    "in the left column, the yellow player would have been forced to drop a yellow piece in the right column on the next turn, guranteeing red a \n",
    "win thereafter. Thus, while our heuristic generally performs well, in this case it would lose the game whereas the more poorly defined\n",
    "heuristic from the tutorial would still give the red player a 50% chance of winning. \n",
    "'''\n",
    "#q_2.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc16816b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.671262Z",
     "iopub.status.busy": "2023-02-23T09:15:46.670846Z",
     "iopub.status.idle": "2023-02-23T09:15:46.679685Z",
     "shell.execute_reply": "2023-02-23T09:15:46.678579Z"
    },
    "papermill": {
     "duration": 0.017682,
     "end_time": "2023-02-23T09:15:46.682385",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.664703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"2_BothLose\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> The agent has two choices: it can play in either column 0 (the leftmost column), or column 6 (the rightmost column). If the agent plays in column 0, it definitely wins the game in its next move.  And, if it plays in column 6, it likely loses the game (since, if the opponent responds by playing in the same column, then the opponent wins the game). \n",
       "\n",
       "If the agent uses the heuristic **from the tutorial**, both columns are scored equally, and so the agent will select from them (uniformly) at random.  In this case, the agent has about a 50/50 chance of winning the game. \n",
       "\n",
       "As for the heuristic **that** **you just implemented**, this will depend on your implementation, so we'll provide an answer for the solution heuristic that we provided -- in this case, the agent most likely loses the game, since it will definitely select the final column. \n",
       "\n",
       "This is an interesting situation, because on average, we see that the agent with the new heuristic performs better than the agent from the tutorial (and yet, for this board, it's guaranteed to make the wrong decision)."
      ],
      "text/plain": [
       "Solution: The agent has two choices: it can play in either column 0 (the leftmost column), or column 6 (the rightmost column). If the agent plays in column 0, it definitely wins the game in its next move.  And, if it plays in column 6, it likely loses the game (since, if the opponent responds by playing in the same column, then the opponent wins the game). \n",
       "\n",
       "If the agent uses the heuristic **from the tutorial**, both columns are scored equally, and so the agent will select from them (uniformly) at random.  In this case, the agent has about a 50/50 chance of winning the game. \n",
       "\n",
       "As for the heuristic **that** **you just implemented**, this will depend on your implementation, so we'll provide an answer for the solution heuristic that we provided -- in this case, the agent most likely loses the game, since it will definitely select the final column. \n",
       "\n",
       "This is an interesting situation, because on average, we see that the agent with the new heuristic performs better than the agent from the tutorial (and yet, for this board, it's guaranteed to make the wrong decision)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383de174",
   "metadata": {
    "papermill": {
     "duration": 0.004796,
     "end_time": "2023-02-23T09:15:46.692223",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.687427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3) Submit to the competition\n",
    "\n",
    "Now, it's time to submit an agent to the competition!  Use the next code cell to define an agent.  (You can see an example of how to write a valid agent in **[this notebook](https://www.kaggle.com/alexisbcook/create-a-connectx-agent)**.)\n",
    "\n",
    "You're encouraged to use what you learned in the first question of this exercise to write an agent.  Use the code from the tutorial as a starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b6f427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.704025Z",
     "iopub.status.busy": "2023-02-23T09:15:46.703605Z",
     "iopub.status.idle": "2023-02-23T09:15:46.732011Z",
     "shell.execute_reply": "2023-02-23T09:15:46.730741Z"
    },
    "papermill": {
     "duration": 0.037242,
     "end_time": "2023-02-23T09:15:46.734367",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.697125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    op_gains = []\\n    for move in valid_moves:\\n        new_grid = drop_piece(grid, move, obs.mark, config)\\n        if new_grid[0][move] == 0:\\n            op_gains.append(score_move(new_grid, move, obs.mark % 2 + 1, config))\\n        else:\\n            op_gains.append(0)\\n    delta = np.asarray(scores) - np.asarray(op_gains)\\n    return valid_moves[delta.argmax()]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "    \n",
    "# Calculates score if agent drops piece in selected column\n",
    "def score_move(grid, col, mark, config):\n",
    "    next_grid = drop_piece(grid, col, mark, config)\n",
    "    score = get_heuristic_q1(next_grid, mark, config)\n",
    "    return score\n",
    "\n",
    "# Helper function for score_move: gets board at next step if agent drops piece in selected column\n",
    "def drop_piece(grid, col, mark, config):\n",
    "    next_grid = grid.copy()\n",
    "    for row in range(config.rows-1, -1, -1):\n",
    "        if next_grid[row][col] == 0:\n",
    "            break\n",
    "    next_grid[row][col] = mark\n",
    "    return next_grid\n",
    "\n",
    "# Helper function for score_move: calculates value of heuristic for grid\n",
    "def get_heuristic_q1(grid, col, mark, config):\n",
    "    num_twos = count_windows(grid, 2, mark, config)\n",
    "    num_threes = count_windows(grid, 3, mark, config)\n",
    "    num_fours = count_windows(grid, 4, mark, config)\n",
    "    num_twos_opp = count_windows(grid, 2, mark%2+1, config)\n",
    "    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "    score = A*num_fours + B*num_threes + C*num_twos + D*num_twos_opp + E*num_threes_opp\n",
    "    return score\n",
    "\n",
    "# Helper function for get_heuristic: checks if window satisfies heuristic conditions\n",
    "def check_window(window, num_discs, piece, config):\n",
    "    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
    "    \n",
    "# Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n",
    "def count_windows(grid, num_discs, piece, config):\n",
    "    num_windows = 0\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    return num_windows\n",
    "\n",
    "def my_agent(obs, config):\n",
    "    # Your code here: Amend the agent!\n",
    "    valid_moves = [col for col in range(config.columns) if obs.board[col] == 0]\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config) for col in valid_moves]))\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    return random.choice(max_cols)\n",
    "'''\n",
    "    op_gains = []\n",
    "    for move in valid_moves:\n",
    "        new_grid = drop_piece(grid, move, obs.mark, config)\n",
    "        if new_grid[0][move] == 0:\n",
    "            op_gains.append(score_move(new_grid, move, obs.mark % 2 + 1, config))\n",
    "        else:\n",
    "            op_gains.append(0)\n",
    "    delta = np.asarray(scores) - np.asarray(op_gains)\n",
    "    return valid_moves[delta.argmax()]\n",
    "'''\n",
    "# was trying to impliment something where the above descibed\n",
    "# senario cannot happen by making sure the opponent does not \n",
    "# benefit from your move in their heuristic score in that column\n",
    "# and overall, revisit later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bc51f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.747063Z",
     "iopub.status.busy": "2023-02-23T09:15:46.746077Z",
     "iopub.status.idle": "2023-02-23T09:15:46.754087Z",
     "shell.execute_reply": "2023-02-23T09:15:46.753192Z"
    },
    "papermill": {
     "duration": 0.016633,
     "end_time": "2023-02-23T09:15:46.756264",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.739631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_CreateAgentEx2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Thank you for creating an agent!</span>"
      ],
      "text/plain": [
       "Thank you for creating an agent!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this code cell to get credit for creating an agent\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bfe95",
   "metadata": {
    "papermill": {
     "duration": 0.005023,
     "end_time": "2023-02-23T09:15:46.766682",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.761659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run the next code cell to convert your agent to a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc164502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T09:15:46.779690Z",
     "iopub.status.busy": "2023-02-23T09:15:46.778404Z",
     "iopub.status.idle": "2023-02-23T09:15:46.788216Z",
     "shell.execute_reply": "2023-02-23T09:15:46.786554Z"
    },
    "papermill": {
     "duration": 0.018671,
     "end_time": "2023-02-23T09:15:46.790559",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.771888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function my_agent at 0x7f689fe49440> written to submission.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "def write_agent_to_file(function, file):\n",
    "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
    "        f.write(inspect.getsource(function))\n",
    "        print(function, \"written to\", file)\n",
    "\n",
    "write_agent_to_file(my_agent, \"submission.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61edc5ab",
   "metadata": {
    "papermill": {
     "duration": 0.005086,
     "end_time": "2023-02-23T09:15:46.801326",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.796240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then, follow these steps to submit your agent to the competition:\n",
    "1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n",
    "2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n",
    "3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n",
    "\n",
    "You have now successfully submitted to the competition!\n",
    "\n",
    "If you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n",
    "\n",
    "\n",
    "Go to **\"My Submissions\"** to view your score and episodes being played.\n",
    "\n",
    "# Keep going\n",
    "\n",
    "Move on to **[develop a longer-term strategy](https://www.kaggle.com/alexisbcook/n-step-lookahead)** with the minimax algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fc051",
   "metadata": {
    "papermill": {
     "duration": 0.005094,
     "end_time": "2023-02-23T09:15:46.811895",
     "exception": false,
     "start_time": "2023-02-23T09:15:46.806801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.045091,
   "end_time": "2023-02-23T09:15:47.539175",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-23T09:15:19.494084",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
