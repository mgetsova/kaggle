{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e56439",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-26T06:06:12.467886Z",
     "iopub.status.busy": "2023-04-26T06:06:12.467442Z",
     "iopub.status.idle": "2023-04-26T06:10:54.429455Z",
     "shell.execute_reply": "2023-04-26T06:10:54.428170Z"
    },
    "papermill": {
     "duration": 281.972733,
     "end_time": "2023-04-26T06:10:54.432987",
     "exception": false,
     "start_time": "2023-04-26T06:06:12.460254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'software': No such file or directory\r\n",
      "Processing ./software/dependencies/torch-1.11.0+cu115-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0+cu115) (4.1.1)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0\r\n",
      "    Uninstalling torch-1.11.0:\r\n",
      "      Successfully uninstalled torch-1.11.0\r\n",
      "Successfully installed torch-1.11.0+cu115\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-cluster\r\n",
      "Successfully installed torch-cluster-1.6.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-scatter\r\n",
      "Successfully installed torch-scatter-2.0.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-sparse==0.6.13) (1.7.3)\r\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from scipy->torch-sparse==0.6.13) (1.21.6)\r\n",
      "Installing collected packages: torch-sparse\r\n",
      "Successfully installed torch-sparse-0.6.13\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_geometric-2.0.4.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (4.64.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.21.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.7.3)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.3.5)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (2.28.1)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (3.0.9)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->torch-geometric==2.0.4) (2.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric==2.0.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric==2.0.4) (2022.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (3.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric==2.0.4) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric==2.0.4) (3.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric==2.0.4) (1.15.0)\r\n",
      "Building wheels for collected packages: torch-geometric\r\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=c0b687174bf6316d24b43cc9daa370867180704e2f1ba4e1b69cb9cf68496194\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/33/a3/07aa146f758cd91ebee36268011873ae31c2cfc59dec089e04\r\n",
      "Successfully built torch-geometric\r\n",
      "Installing collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.0.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: /kaggle/working/software/dependencies\r\n",
      "Obtaining file:///kaggle/working/software/graphnet\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/working/software/dependencies/awkward-1.8.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: colorlog>=6.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (6.7.0)\r\n",
      "Processing /kaggle/working/software/dependencies/ConfigUpdater-3.1.1-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.3.6)\r\n",
      "Requirement already satisfied: matplotlib>=3.5 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (3.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.21.6)\r\n",
      "Requirement already satisfied: pandas<2.0,>=1.3 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.3.5)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (5.0.0)\r\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.8.2)\r\n",
      "Processing /kaggle/working/software/dependencies/ruamel.yaml-0.17.21-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit_learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.7.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.4.39)\r\n",
      "Processing /kaggle/working/software/dependencies/timer-0.2.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm>=4.64 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (4.64.0)\r\n",
      "Requirement already satisfied: wandb>=0.12 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.12.21)\r\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.11.0+cu115)\r\n",
      "Requirement already satisfied: torch-cluster>=1.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.6.0)\r\n",
      "Requirement already satisfied: torch-scatter>=2.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (2.0.9)\r\n",
      "Requirement already satisfied: torch-sparse>=0.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.6.13)\r\n",
      "Requirement already satisfied: torch-geometric>=2.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (2.0.4)\r\n",
      "Requirement already satisfied: pytorch-lightning<2.0,>=1.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.9.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from awkward<2.0,>=1.8->graphnet==0.2.4+328.g62eb86c8) (59.8.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (9.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (2.8.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (4.33.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (3.0.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (0.11.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (23.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (1.4.3)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.3->graphnet==0.2.4+328.g62eb86c8) (2022.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (4.1.1)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.11.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.5.0)\r\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (2023.1.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (6.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>=1.0->graphnet==0.2.4+328.g62eb86c8) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>=1.0->graphnet==0.2.4+328.g62eb86c8) (1.0.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (6.0.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (1.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.28.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (3.1.2)\r\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.20.3)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (0.1.2)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (8.1.3)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.1.27)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.0.11)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (0.4.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.15.0)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (2.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (5.9.1)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.3.2)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.13.0)\r\n",
      "Processing /kaggle/working/software/dependencies/ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (3.8.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (4.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (3.8.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2022.12.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.1.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.7.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (21.4.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (6.0.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.3.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.13.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (4.0.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.2.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.0.5)\r\n",
      "Installing collected packages: timer, ruamel.yaml.clib, awkward, ruamel.yaml, configupdater, graphnet\r\n",
      "  Running setup.py develop for graphnet\r\n",
      "Successfully installed awkward-1.8.0 configupdater-3.1.1 graphnet-0.2.4+328.g62eb86c8 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 timer-0.2.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Move software to working disk\n",
    "!rm  -r software\n",
    "!scp -r /kaggle/input/graphnet-and-dependencies/software .\n",
    "\n",
    "# Install dependencies\n",
    "!pip install /kaggle/working/software/dependencies/torch-1.11.0+cu115-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_geometric-2.0.4.tar.gz\n",
    "\n",
    "!cd software/graphnet;pip install --no-index --find-links=\"/kaggle/working/software/dependencies\" -e .[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a21851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:54.451503Z",
     "iopub.status.busy": "2023-04-26T06:10:54.451151Z",
     "iopub.status.idle": "2023-04-26T06:10:54.528085Z",
     "shell.execute_reply": "2023-04-26T06:10:54.526607Z"
    },
    "papermill": {
     "duration": 0.089023,
     "end_time": "2023-04-26T06:10:54.530712",
     "exception": false,
     "start_time": "2023-04-26T06:10:54.441689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install GraphNeT\n",
    "import sys\n",
    "#sys.path.append('/kaggle/input/graphnet/graphnet/src')\n",
    "sys.path.append('/kaggle/working/software/graphnet/src')\n",
    "import graphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4f05ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:54.550781Z",
     "iopub.status.busy": "2023-04-26T06:10:54.549783Z",
     "iopub.status.idle": "2023-04-26T06:10:55.538106Z",
     "shell.execute_reply": "2023-04-26T06:10:55.536892Z"
    },
    "papermill": {
     "duration": 1.001666,
     "end_time": "2023-04-26T06:10:55.540835",
     "exception": false,
     "start_time": "2023-04-26T06:10:54.539169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyarrow \n",
    "\n",
    "DATA_PATH = '/kaggle/input/icecube-neutrinos-in-deep-ice/'\n",
    "SENSORS = DATA_PATH + 'sensor_geometry.csv'\n",
    "TRANSPERANCY = '/kaggle/input/icecube-additional/ice_transperancy.txt'\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/icecube-utils/')\n",
    "from prepare_sensors import prepare_sensors\n",
    "from ice_transparency import ice_transparency\n",
    "sensor_df = prepare_sensors(SENSORS)\n",
    "f_scattering, f_absorption = ice_transparency(TRANSPERANCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe76c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:55.558882Z",
     "iopub.status.busy": "2023-04-26T06:10:55.558545Z",
     "iopub.status.idle": "2023-04-26T06:10:55.564321Z",
     "shell.execute_reply": "2023-04-26T06:10:55.563219Z"
    },
    "papermill": {
     "duration": 0.017468,
     "end_time": "2023-04-26T06:10:55.566598",
     "exception": false,
     "start_time": "2023-04-26T06:10:55.549130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "META_PATH = '/kaggle/input/batched-metadata/'\n",
    "def get_metadata_pd(batch, write=False):\n",
    "    if batch < 661:\n",
    "        return pd.read_parquet(META_PATH + f'train_meta_batches/batch_{batch}.parquet', \n",
    "                        engine=\"pyarrow\", use_threads=True)\n",
    "    elif batch == 661:\n",
    "        return pd.read_parquet(META_PATH + f'test_meta_batches/batch_{batch}.parquet', \n",
    "                        engine=\"pyarrow\", use_threads=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eaf8595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:55.583316Z",
     "iopub.status.busy": "2023-04-26T06:10:55.582854Z",
     "iopub.status.idle": "2023-04-26T06:10:59.718448Z",
     "shell.execute_reply": "2023-04-26T06:10:59.717231Z"
    },
    "papermill": {
     "duration": 4.146665,
     "end_time": "2023-04-26T06:10:59.720903",
     "exception": false,
     "start_time": "2023-04-26T06:10:55.574238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from graphnet.training.labels import Label\n",
    "\n",
    "class Direction(Label):\n",
    "    \"\"\"Class for producing my label.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Construct `MyCustomLabel`.\"\"\"\n",
    "        # Base class constructor\n",
    "        super().__init__(key=\"direction\")\n",
    "\n",
    "    def __call__(self, graph: Data) -> torch.tensor:\n",
    "        \"\"\"Compute label for `graph`.\"\"\"\n",
    "        zenith = graph.y[0]\n",
    "        azimuth = graph.y[1] # assuming y is a pandas dataframe\n",
    "               \n",
    "        dir_x = (torch.cos(azimuth) * torch.sin(zenith)).reshape(1)\n",
    "        dir_y = (torch.sin(azimuth) * torch.sin(zenith)).reshape(1)\n",
    "        dir_z = torch.cos(zenith).reshape(1)\n",
    "        direction = torch.cat([dir_x, dir_y, dir_z], dim=0)\n",
    "        return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11500d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:59.740839Z",
     "iopub.status.busy": "2023-04-26T06:10:59.738992Z",
     "iopub.status.idle": "2023-04-26T06:10:59.853851Z",
     "shell.execute_reply": "2023-04-26T06:10:59.852906Z"
    },
    "papermill": {
     "duration": 0.126847,
     "end_time": "2023-04-26T06:10:59.856142",
     "exception": false,
     "start_time": "2023-04-26T06:10:59.729295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from typing import (\n",
    "    cast,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Union,\n",
    "    Iterable,\n",
    ")\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, event_ids, batch_id, PATH_TO_BATCH_FILES, \n",
    "                 f_scattering, f_absorption, sensor_df, y, x_features, y_features,\n",
    "                 pulse_limit=300, include_auxiliary=True, construct_graph=False,\n",
    "                 transform = None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "        self.event_ids = event_ids\n",
    "        self.batch_df = pd.read_parquet(PATH_TO_BATCH_FILES + f\"batch_{batch_id}.parquet\")\n",
    "        self.sensor_df = sensor_df\n",
    "        self.pulse_limit = pulse_limit\n",
    "        self.f_scattering = f_scattering\n",
    "        self.f_absorption = f_absorption\n",
    "        self.y = y\n",
    "        self.x_features = x_features\n",
    "        if include_auxiliary == False and 'auxiliary' in self.x_features:\n",
    "            self.x_features.remove('auxiliary')\n",
    "        self.include_auxiliary = include_auxiliary\n",
    "        self.y_features = y_features\n",
    "        self.construct_graph = construct_graph\n",
    "        self._label_fns = dict()\n",
    "        \n",
    "        \n",
    "        # weird scaling...really don't get any of the scaling stuff\n",
    "        self.batch_df[\"time\"] = (self.batch_df[\"time\"] - 1.0e04) / 3.0e4\n",
    "        self.batch_df[\"charge\"] = np.log10(self.batch_df[\"charge\"]) / 3.0\n",
    "        self.batch_df[\"auxiliary\"] = self.batch_df[\"auxiliary\"].astype(int) - 0.5\n",
    "       \n",
    "    def len(self):\n",
    "        return len(self.event_ids)\n",
    "    \n",
    "    def get_dir_vector(self, azimuth, zenith):\n",
    "        dir_x = np.cos(azimuth) * np.sin(zenith)\n",
    "        dir_y = np.sin(azimuth) * np.sin(zenith)\n",
    "        dir_z = np.cos(zenith)\n",
    "        directions = pd.Series({'direction_x':dir_x, 'direction_y':dir_y, 'direction_z':dir_z})\n",
    "        return directions\n",
    "    \n",
    "    def add_label(\n",
    "        self, fn: Callable[[Data], Any], key: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Add custom graph label define using function `fn`.\"\"\"\n",
    "        if isinstance(fn, Label):\n",
    "            key = fn.key\n",
    "        assert isinstance(\n",
    "            key, str\n",
    "        ), \"Please specify a key for the custom label to be added.\"\n",
    "        assert (\n",
    "            key not in self._label_fns\n",
    "        ), f\"A custom label {key} has already been defined.\"\n",
    "        self._label_fns[key] = fn\n",
    "\n",
    "    def get(self, idx):\n",
    "        event_id = self.event_ids[idx]\n",
    "        event = self.batch_df.loc[event_id]\n",
    "        event = pd.merge(event, self.sensor_df, on=\"sensor_id\")\n",
    "        if self.include_auxiliary == False:\n",
    "            event.drop(event[event.auxiliary == 0.5].index)\n",
    "        \n",
    "        x_feats = self.x_features.copy()\n",
    "        if 'scattering' in self.x_features:\n",
    "            x_feats.remove('scattering')\n",
    "        if 'absorption' in self.x_features:\n",
    "            x_feats.remove('absorption')\n",
    "        x = event[x_feats].values\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        data = Data(x=x, n_pulses=torch.tensor(x.shape[0], dtype=torch.int32), features=x_feats)\n",
    "\n",
    "        # Add ice transparency data\n",
    "        z = data.x[:, 2].numpy()\n",
    "        if 'scattering' in self.x_features:\n",
    "            scattering = torch.tensor(self.f_scattering(z), dtype=torch.float32).view(-1, 1)\n",
    "            data.x = torch.cat([data.x, scattering], dim=1)\n",
    "        if 'absorption' in self.x_features:\n",
    "            absorption = torch.tensor(self.f_absorption(z), dtype=torch.float32).view(-1, 1)\n",
    "            data.x = torch.cat([data.x, absorption], dim=1)\n",
    "\n",
    "        # Downsample the large events\n",
    "        if data.n_pulses > self.pulse_limit:\n",
    "            data.x = data.x[np.random.choice(data.n_pulses, self.pulse_limit)]\n",
    "            data.n_pulses = torch.tensor(self.pulse_limit, dtype=torch.int32)\n",
    "\n",
    "        # Builds graph from the k-nearest neighbours.\n",
    "        if self.construct_graph == True:\n",
    "            data.edge_index = knn_graph(\n",
    "                data.x[:, [0, 1, 2]],  # x, y, z\n",
    "                k=8,\n",
    "                batch=None,\n",
    "                loop=False\n",
    "            )\n",
    "        if self.y is not None:\n",
    "            y = self.y.loc[idx, :].values\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "            data.y = y\n",
    "            if self._label_fns:\n",
    "                for key in self._label_fns:\n",
    "                    data[key] = self._label_fns[key](data)\n",
    "            \n",
    "            '''\n",
    "            data.azimuth = self.y.loc[idx][self.y_features].azimuth\n",
    "            data.zenith = self.y.loc[idx][self.y_features].zenith\n",
    "            dirs = self.get_dir_vector(data.azimuth, data.zenith)\n",
    "            data.direction = torch.tensor(self.get_dir_vector(data.azimuth, data.zenith).values)\n",
    "            torch.reshape(data.direction, (1,3))\n",
    "            '''\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eeee035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:10:59.874391Z",
     "iopub.status.busy": "2023-04-26T06:10:59.872925Z",
     "iopub.status.idle": "2023-04-26T06:11:00.187884Z",
     "shell.execute_reply": "2023-04-26T06:11:00.186578Z"
    },
    "papermill": {
     "duration": 0.326335,
     "end_time": "2023-04-26T06:11:00.190437",
     "exception": false,
     "start_time": "2023-04-26T06:10:59.864102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction_x</th>\n",
       "      <th>direction_y</th>\n",
       "      <th>direction_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271161</td>\n",
       "      <td>-0.826088</td>\n",
       "      <td>-0.494015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913804</td>\n",
       "      <td>0.405607</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268879</td>\n",
       "      <td>0.618078</td>\n",
       "      <td>-0.738704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623491</td>\n",
       "      <td>-0.291423</td>\n",
       "      <td>0.725488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.490794</td>\n",
       "      <td>0.590501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direction_x  direction_y  direction_z\n",
       "0     0.271161    -0.826088    -0.494015\n",
       "1     0.913804     0.405607     0.021108\n",
       "2     0.268879     0.618078    -0.738704\n",
       "3     0.623491    -0.291423     0.725488\n",
       "4     0.640648     0.490794     0.590501"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_ID = 1\n",
    "TRAIN_PATH = DATA_PATH + 'train/'\n",
    "batch_meta = get_metadata_pd(BATCH_ID, write=False)\n",
    "event_ids = list(batch_meta['event_id'])\n",
    "#x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering', 'absorption']\n",
    "#x_feats = ['x', 'y', 'z', 'time', \"charge\", \"auxiliary\"]\n",
    "x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering']\n",
    "y_feats = ['zenith', 'azimuth']\n",
    "y = batch_meta[y_feats].reset_index(drop=True)\n",
    "dir_x = np.cos(y.azimuth) * np.sin(y.zenith)\n",
    "dir_y = np.sin(y.azimuth) * np.sin(y.zenith)\n",
    "dir_z = np.cos(y.zenith)\n",
    "directions = pd.concat({'direction_x':dir_x, 'direction_y':dir_y, 'direction_z':dir_z}, axis = 1)\n",
    "directions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b28428c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:00.210897Z",
     "iopub.status.busy": "2023-04-26T06:11:00.209895Z",
     "iopub.status.idle": "2023-04-26T06:11:06.707334Z",
     "shell.execute_reply": "2023-04-26T06:11:06.706242Z"
    },
    "papermill": {
     "duration": 6.510556,
     "end_time": "2023-04-26T06:11:06.710396",
     "exception": false,
     "start_time": "2023-04-26T06:11:00.199840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = IceCubeDataset(event_ids, BATCH_ID, TRAIN_PATH, f_scattering, \n",
    "                         f_absorption, sensor_df, y, x_feats, y_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab325a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:06.728501Z",
     "iopub.status.busy": "2023-04-26T06:11:06.728144Z",
     "iopub.status.idle": "2023-04-26T06:11:06.735977Z",
     "shell.execute_reply": "2023-04-26T06:11:06.734967Z"
    },
    "papermill": {
     "duration": 0.019405,
     "end_time": "2023-04-26T06:11:06.737995",
     "exception": false,
     "start_time": "2023-04-26T06:11:06.718590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[32mINFO    \u001b[0m 2023-04-26 06:11:06 - Direction._configure_root_logger - Writing log to \u001b[1mlogs/graphnet_20230426-061106.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset.add_label(Direction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb65cfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:06.756399Z",
     "iopub.status.busy": "2023-04-26T06:11:06.755533Z",
     "iopub.status.idle": "2023-04-26T06:11:08.213836Z",
     "shell.execute_reply": "2023-04-26T06:11:08.212768Z"
    },
    "papermill": {
     "duration": 1.469821,
     "end_time": "2023-04-26T06:11:08.216236",
     "exception": false,
     "start_time": "2023-04-26T06:11:06.746415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2712, -0.8261, -0.4940])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get(0)['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce88b475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.234450Z",
     "iopub.status.busy": "2023-04-26T06:11:08.234155Z",
     "iopub.status.idle": "2023-04-26T06:11:08.241597Z",
     "shell.execute_reply": "2023-04-26T06:11:08.240770Z"
    },
    "papermill": {
     "duration": 0.01909,
     "end_time": "2023-04-26T06:11:08.243876",
     "exception": false,
     "start_time": "2023-04-26T06:11:08.224786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = x_feats\n",
    "truth = y_feats\n",
    "\n",
    "config = {\n",
    "        #\"path\": '/kaggle/working/batch_1.db',\n",
    "        #\"inference_database_path\": '/kaggle/working/batch_51.db',\n",
    "        #\"pulsemap\": 'pulse_table',\n",
    "        #\"truth_table\": 'meta_table',\n",
    "        'neighbours': 8,\n",
    "        'graph_builder_columns' : [0, 1, 2], # x, y, z\n",
    "        'global_pooling_schemes' : [\"min\", \"max\", \"mean\"],\n",
    "        \"features\": features,\n",
    "        #\"truth\": truth,\n",
    "        \"index_column\": 'event_id',\n",
    "        #\"run_name_tag\": 'my_example',\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 2,\n",
    "        \"target\": 'direction',\n",
    "        \"early_stopping_patience\": 5,\n",
    "        \"fit\": {\n",
    "                \"max_epochs\": 10,\n",
    "                \"gpus\": [0],\n",
    "                \"distribution_strategy\": None,\n",
    "                },\n",
    "        #'train_selection': '/kaggle/working/train_selection_max_200_pulses.csv',\n",
    "        #'validate_selection': '/kaggle/working/validate_selection_max_200_pulses.csv',\n",
    "        #'test_selection': None,\n",
    "        #'base_dir': 'training'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee547f8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.261032Z",
     "iopub.status.busy": "2023-04-26T06:11:08.260771Z",
     "iopub.status.idle": "2023-04-26T06:11:08.628952Z",
     "shell.execute_reply": "2023-04-26T06:11:08.627872Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.379756,
     "end_time": "2023-04-26T06:11:08.631462",
     "exception": false,
     "start_time": "2023-04-26T06:11:08.251706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Any, Optional, Union, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn.functional import (\n",
    "    one_hot,\n",
    "    cross_entropy,\n",
    "    binary_cross_entropy,\n",
    "    softplus,\n",
    ")\n",
    "\n",
    "from graphnet.utilities.config import save_model_config\n",
    "from graphnet.models.model import Model\n",
    "from graphnet.utilities.decorators import final\n",
    "\n",
    "\n",
    "class LossFunction(Model):\n",
    "    \"\"\"Base class for loss functions in `graphnet`.\"\"\"\n",
    "\n",
    "    @save_model_config\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Construct `LossFunction`, saving model config.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @final\n",
    "    def forward(  # type: ignore[override]\n",
    "        self,\n",
    "        prediction: Tensor,\n",
    "        target: Tensor,\n",
    "        weights: Optional[Tensor] = None,\n",
    "        return_elements: bool = False,\n",
    "    ) -> Tensor:\n",
    "        print('in lossfunction class forward------')\n",
    "        \"\"\"Forward pass for all loss functions.\n",
    "\n",
    "        Args:\n",
    "            prediction: Tensor containing predictions. Shape [N,P]\n",
    "            target: Tensor containing targets. Shape [N,T]\n",
    "            return_elements: Whether elementwise loss terms should be returned.\n",
    "                The alternative is to return the averaged loss across examples.\n",
    "\n",
    "        Returns:\n",
    "            Loss, either averaged to a scalar (if `return_elements = False`) or\n",
    "            elementwise terms with shape [N,] (if `return_elements = True`).\n",
    "        \"\"\"\n",
    "        elements = self._forward(prediction, target)\n",
    "        if weights is not None:\n",
    "            elements = elements * weights\n",
    "            \n",
    "        if (elements.size(dim=0) != target.size(dim=0)):\n",
    "            print(elements.shape)\n",
    "            print(target.shape)\n",
    "        #assert elements.size(dim=0) == target.size(dim=0), \n",
    "\n",
    "class VonMisesFisherLoss(LossFunction):\n",
    "    \"\"\"General class for calculating von Mises-Fisher loss.\n",
    "\n",
    "    Requires implementation for specific dimension `m` in which the target and\n",
    "    prediction vectors need to be prepared.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def log_cmk_exact(\n",
    "        cls, m: int, kappa: Tensor\n",
    "    ) -> Tensor:  # pylint: disable=invalid-name\n",
    "        \"\"\"Calculate $log C_{m}(k)$ term in von Mises-Fisher loss exactly.\"\"\"\n",
    "        return LogCMK.apply(m, kappa)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def log_cmk_approx(\n",
    "        cls, m: int, kappa: Tensor\n",
    "    ) -> Tensor:  # pylint: disable=invalid-name\n",
    "        \"\"\"Calculate $log C_{m}(k)$ term in von Mises-Fisher loss approx.\n",
    "\n",
    "        [https://arxiv.org/abs/1812.04616] Sec. 8.2 with additional minus sign.\n",
    "        \"\"\"\n",
    "        v = m / 2.0 - 0.5\n",
    "        a = torch.sqrt((v + 1) ** 2 + kappa**2)\n",
    "        b = v - 1\n",
    "        return -a + b * torch.log(b + a)\n",
    "    def log_cmk(\n",
    "        cls, m: int, kappa: Tensor, kappa_switch: float = 100.0\n",
    "    ) -> Tensor:  # pylint: disable=invalid-name\n",
    "        \"\"\"Calculate $log C_{m}(k)$ term in von Mises-Fisher loss.\n",
    "\n",
    "        Since `log_cmk_exact` is diverges for `kappa` >~ 700 (using float64\n",
    "        precision), and since `log_cmk_approx` is unaccurate for small `kappa`,\n",
    "        this method automatically switches between the two at `kappa_switch`,\n",
    "        ensuring continuity at this point.\n",
    "        \"\"\"\n",
    "        kappa_switch = torch.tensor([kappa_switch]).to(kappa.device)\n",
    "        mask_exact = kappa < kappa_switch\n",
    "\n",
    "        # Ensure continuity at `kappa_switch`\n",
    "        offset = cls.log_cmk_approx(m, kappa_switch) - cls.log_cmk_exact(\n",
    "            m, kappa_switch\n",
    "        )\n",
    "        ret = cls.log_cmk_approx(m, kappa) - offset\n",
    "        ret[mask_exact] = cls.log_cmk_exact(m, kappa[mask_exact])\n",
    "        return ret\n",
    "\n",
    "    def _evaluate(self, prediction: Tensor, target: Tensor) -> Tensor:\n",
    "        print('in von gneral evaluate------')\n",
    "        \"\"\"Calculate von Mises-Fisher loss for a vector in D dimensons.\n",
    "\n",
    "        This loss utilises the von Mises-Fisher distribution, which is a\n",
    "        probability distribution on the (D - 1) sphere in D-dimensional space.\n",
    "\n",
    "        Args:\n",
    "            prediction: Predicted vector, of shape [batch_size, D].\n",
    "            target: Target unit vector, of shape [batch_size, D].\n",
    "\n",
    "        Returns:\n",
    "            Elementwise von Mises-Fisher loss terms.\n",
    "        \"\"\"\n",
    "        # Check(s)\n",
    "        assert prediction.dim() == 2\n",
    "        assert target.dim() == 2\n",
    "        assert prediction.size() == target.size()\n",
    "\n",
    "        # Computing loss\n",
    "        m = target.size()[1]\n",
    "        k = torch.norm(prediction, dim=1)\n",
    "        dotprod = torch.sum(prediction * target, dim=1)\n",
    "        elements = -self.log_cmk(m, k) - dotprod\n",
    "        return elements\n",
    "\n",
    "    @abstractmethod\n",
    "    def _forward(self, prediction: Tensor, target: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class VonMisesFisher3DLoss(VonMisesFisherLoss):\n",
    "    \"\"\"von Mises-Fisher loss function vectors in the 3D plane.\"\"\"\n",
    "\n",
    "    def _forward(self, prediction: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"Calculate von Mises-Fisher loss for a direction in the 3D.\n",
    "\n",
    "        Args:\n",
    "            prediction: Output of the model. Must have shape [N, 4] where\n",
    "                columns 0, 1, 2 are predictions of `direction` and last column\n",
    "                is an estimate of `kappa`.\n",
    "            target: Target tensor, extracted from graph object.\n",
    "\n",
    "        Returns:\n",
    "            Elementwise von Mises-Fisher loss terms. Shape [N,]\n",
    "        \"\"\"\n",
    "        \n",
    "        print('in Von3d ---')\n",
    "        print(target.shape)\n",
    "        target = target.reshape(-1, 3)\n",
    "        print('after reshape')\n",
    "        print(target.shape)\n",
    "        # Check(s)\n",
    "        assert prediction.dim() == 2 and prediction.size()[1] == 4\n",
    "        assert target.dim() == 2\n",
    "        assert prediction.size()[0] == target.size()[0]\n",
    "\n",
    "        kappa = prediction[:, 3]\n",
    "        p = kappa.unsqueeze(1) * prediction[:, [0, 1, 2]]\n",
    "        return self._evaluate(p, target)\n",
    "        \"`_forward` should return elementwise loss terms.\"\n",
    "\n",
    "        return elements if return_elements else torch.mean(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c723743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.648603Z",
     "iopub.status.busy": "2023-04-26T06:11:08.648279Z",
     "iopub.status.idle": "2023-04-26T06:11:08.657769Z",
     "shell.execute_reply": "2023-04-26T06:11:08.656919Z"
    },
    "papermill": {
     "duration": 0.020321,
     "end_time": "2023-04-26T06:11:08.659852",
     "exception": false,
     "start_time": "2023-04-26T06:11:08.639531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Any, Optional, Union, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn.functional import (\n",
    "    one_hot,\n",
    "    cross_entropy,\n",
    "    binary_cross_entropy,\n",
    "    softplus,\n",
    ")\n",
    "\n",
    "from graphnet.utilities.config import save_model_config\n",
    "from graphnet.models.model import Model\n",
    "from graphnet.utilities.decorators import final\n",
    "\n",
    "# overriding graphnet VonMisesFischer3dLoss and parent LossFunction\n",
    "class vMF_Loss(Model):\n",
    "    \"\"\"Base class for loss functions in `graphnet`.\"\"\"\n",
    "\n",
    "    @save_model_config\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Construct `LossFunction`, saving model config.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @final\n",
    "    def forward(  # type: ignore[override]\n",
    "        self,\n",
    "        prediction: Tensor,\n",
    "        target: Tensor,\n",
    "        weights: Optional[Tensor] = None,\n",
    "        return_elements: bool = False,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        target = target.reshape(-1, 3)\n",
    "        \n",
    "        eps = 1e-8\n",
    "        kappa = prediction[:, 3]      \n",
    "        logC  = -kappa + torch.log( ( kappa+eps )/( 1-torch.exp(-2*kappa)+2*eps ) )\n",
    "        p = kappa.unsqueeze(1) * prediction[:, [0, 1, 2]]\n",
    "        return -( (target*p).sum(dim=1) + logC ).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2cb042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.676387Z",
     "iopub.status.busy": "2023-04-26T06:11:08.676132Z",
     "iopub.status.idle": "2023-04-26T06:11:08.855024Z",
     "shell.execute_reply": "2023-04-26T06:11:08.853991Z"
    },
    "papermill": {
     "duration": 0.190312,
     "end_time": "2023-04-26T06:11:08.857662",
     "exception": false,
     "start_time": "2023-04-26T06:11:08.667350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[33mWARNING \u001b[0m 2023-04-26 06:11:08 - warning - `icecube` not available. Some functionality may be missing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, List, Optional, Sequence, Tuple, Union, Dict\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.optim.adam import Adam\n",
    "#from graphnet.data.constants import FEATURES, TRUTH\n",
    "from graphnet.models.standard_model import StandardModel\n",
    "#from graphnet.models.detector.icecube import IceCubeKaggle\n",
    "from graphnet.models.gnn import DynEdge\n",
    "from graphnet.models.graph_builders import KNNGraphBuilder\n",
    "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa, ZenithReconstructionWithKappa, AzimuthReconstructionWithKappa\n",
    "from graphnet.training.callbacks import ProgressBar, PiecewiseLinearLR\n",
    "#from graphnet.training.loss_functions import VonMisesFisher3DLoss, VonMisesFisher2DLoss\n",
    "#from graphnet.training.labels import Direction\n",
    "from graphnet.training.utils import make_dataloader\n",
    "from graphnet.utilities.logging import Logger\n",
    "from pytorch_lightning import Trainer\n",
    "import pandas as pd\n",
    "from graphnet.models.detector.detector import Detector\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "#override graphnet class\n",
    "class IceCubeKaggle(Detector):\n",
    "    \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "    # Implementing abstract class attribute\n",
    "    features = features\n",
    "\n",
    "    def _forward(self, data: Data) -> Data:\n",
    "        \"\"\"Ingest data, build graph, and preprocess features.\n",
    "        Args:\n",
    "            data: Input graph data.\n",
    "        Returns:\n",
    "            Connected and preprocessed graph data.\n",
    "        \"\"\"\n",
    "        # Check(s) --- no we want to have flexible feature inputs\n",
    "        # Preprocessing was already done\n",
    "        data_features = [features[0] for features in data.features]\n",
    "        features = data_features\n",
    "\n",
    "        return data\n",
    "\n",
    "def build_model(config: Dict[str,Any], train_dataloader: Any) -> StandardModel:\n",
    "    \"\"\"Builds GNN from config\"\"\"\n",
    "    # Building model\n",
    "    detector = IceCubeKaggle(\n",
    "        graph_builder=KNNGraphBuilder(nb_nearest_neighbours=config['neighbours'], \n",
    "                                     columns=config['graph_builder_columns']),\n",
    "    )\n",
    "    detector.features = config['features']\n",
    "    gnn = DynEdge(\n",
    "        nb_inputs=detector.nb_outputs,\n",
    "        global_pooling_schemes=config['global_pooling_schemes'],\n",
    "    )\n",
    "\n",
    "   # if config[\"target\"] == 'direction':\n",
    "    task = DirectionReconstructionWithKappa(\n",
    "            hidden_size=gnn.nb_outputs,\n",
    "            target_labels=config[\"target\"],\n",
    "            #loss_function=VonMisesFisher3DLoss(),\n",
    "            loss_function = vMF_Loss(),\n",
    "        )\n",
    "    prediction_columns = [config[\"target\"] + \"_x\", \n",
    "                              config[\"target\"] + \"_y\", \n",
    "                              config[\"target\"] + \"_z\", \n",
    "                              config[\"target\"] + \"_kappa\" ]\n",
    "    additional_attributes = ['zenith', 'azimuth', 'event_id']\n",
    "\n",
    "    model = StandardModel(\n",
    "        detector=detector,\n",
    "        gnn=gnn,\n",
    "        tasks=[task],\n",
    "        optimizer_class=Adam,\n",
    "        optimizer_kwargs={\"lr\": 1e-03, \"eps\": 1e-03},\n",
    "        scheduler_class=PiecewiseLinearLR,\n",
    "        scheduler_kwargs={\n",
    "            \"milestones\": [\n",
    "                0,\n",
    "                len(train_dataloader) / 2,\n",
    "                len(train_dataloader) * config[\"fit\"][\"max_epochs\"],\n",
    "            ],\n",
    "            \"factors\": [1e-02, 1, 1e-02],\n",
    "        },\n",
    "        scheduler_config={\n",
    "            \"interval\": \"step\",\n",
    "        },\n",
    "    )\n",
    "    model.prediction_columns = prediction_columns\n",
    "    model.additional_attributes = additional_attributes\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f186e7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.878594Z",
     "iopub.status.busy": "2023-04-26T06:11:08.876534Z",
     "iopub.status.idle": "2023-04-26T06:11:08.885583Z",
     "shell.execute_reply": "2023-04-26T06:11:08.884553Z"
    },
    "papermill": {
     "duration": 0.021496,
     "end_time": "2023-04-26T06:11:08.887878",
     "exception": false,
     "start_time": "2023-04-26T06:11:08.866382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_step(config: Dict[str, Any], dataset_) -> StandardModel:\n",
    "    \"\"\"Builds and trains GNN according to config.\"\"\"\n",
    "    logger.info(f\"features: {config['features']}\")\n",
    "    logger.info(f\"truth: {config['target']}\")\n",
    "    \n",
    "    #archive = os.path.join(config['base_dir'], \"train_model_without_configs\")\n",
    "    #run_name = f\"dynedge_{config['target']}_{config['run_name_tag']}\"\n",
    "    \n",
    "    # do train-test split as:\n",
    "    train_len = int(0.7*dataset_.len())\n",
    "    train_loader = DataLoader(dataset_[:train_len], batch_size=config['batch_size'], shuffle=True, follow_batch=config['target']) # shuffle data every epoch\n",
    "    val_loader = DataLoader(dataset_[train_len:], batch_size=config['batch_size'], shuffle=False, follow_batch=config['target'])\n",
    "    \n",
    "    model = build_model(config, train_loader)\n",
    "\n",
    "    # Training model\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=config[\"early_stopping_patience\"],\n",
    "        ),\n",
    "        ProgressBar(),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        callbacks=callbacks,\n",
    "        **config[\"fit\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdfc7517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:11:08.907659Z",
     "iopub.status.busy": "2023-04-26T06:11:08.905897Z",
     "iopub.status.idle": "2023-04-26T06:11:09.235421Z",
     "shell.execute_reply": "2023-04-26T06:11:09.233799Z"
    },
    "papermill": {
     "duration": 0.341555,
     "end_time": "2023-04-26T06:11:09.237844",
     "exception": true,
     "start_time": "2023-04-26T06:11:08.896289",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "training_step() missing 1 required positional argument: 'dataset_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25/2926864363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: training_step() missing 1 required positional argument: 'dataset_'"
     ]
    }
   ],
   "source": [
    "model = training_step(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a92047",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-26T03:48:31.218023Z",
     "iopub.status.busy": "2023-04-26T03:48:31.216967Z",
     "iopub.status.idle": "2023-04-26T03:48:31.227571Z",
     "shell.execute_reply": "2023-04-26T03:48:31.226402Z",
     "shell.execute_reply.started": "2023-04-26T03:48:31.217969Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf733c6c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset_for_batch(BATCH_ID):\n",
    "    TRAIN_PATH = DATA_PATH + 'train/'\n",
    "    batch_meta = get_metadata_for_batch(BATCH_ID, write=False)\n",
    "    event_ids = list(batch_meta['event_id'])\n",
    "    #x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering', 'absorption']\n",
    "    #x_feats = ['x', 'y', 'z', 'time', \"charge\", \"auxiliary\"]\n",
    "    x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering']\n",
    "    y_feats = ['zenith', 'azimuth']\n",
    "    y = batch_meta[y_feats].reset_index(drop=True)\n",
    "    return dataset\n",
    "\n",
    "inference_dataset = make_dataset_for_batch(2)\n",
    "# get first 10,000 samples only for batch 2 to do inference on\n",
    "inf_loader = DataLoader(inference_dataset[:10000], batch_size=config['batch_size'], shuffle=False)\n",
    "results = model.predict_as_dataframe(\n",
    "        gpus = [0],\n",
    "        dataloader = inf_loader,\n",
    "        prediction_columns=model.prediction_columns,\n",
    "        additional_attributes=model.additional_attributes,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 307.490523,
   "end_time": "2023-04-26T06:11:12.044703",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-26T06:06:04.554180",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
