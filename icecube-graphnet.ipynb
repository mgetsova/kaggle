{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85ad5ee",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-26T06:46:45.543504Z",
     "iopub.status.busy": "2023-04-26T06:46:45.543000Z",
     "iopub.status.idle": "2023-04-26T06:51:22.307015Z",
     "shell.execute_reply": "2023-04-26T06:51:22.305831Z"
    },
    "papermill": {
     "duration": 276.774168,
     "end_time": "2023-04-26T06:51:22.309955",
     "exception": false,
     "start_time": "2023-04-26T06:46:45.535787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'software': No such file or directory\r\n",
      "Processing ./software/dependencies/torch-1.11.0+cu115-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0+cu115) (4.1.1)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0\r\n",
      "    Uninstalling torch-1.11.0:\r\n",
      "      Successfully uninstalled torch-1.11.0\r\n",
      "Successfully installed torch-1.11.0+cu115\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-cluster\r\n",
      "Successfully installed torch-cluster-1.6.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-scatter\r\n",
      "Successfully installed torch-scatter-2.0.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-sparse==0.6.13) (1.7.3)\r\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from scipy->torch-sparse==0.6.13) (1.21.6)\r\n",
      "Installing collected packages: torch-sparse\r\n",
      "Successfully installed torch-sparse-0.6.13\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./software/dependencies/torch_geometric-2.0.4.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (4.64.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.21.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.7.3)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.3.5)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (2.28.1)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (3.0.9)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torch-geometric==2.0.4) (1.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->torch-geometric==2.0.4) (2.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric==2.0.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric==2.0.4) (2022.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric==2.0.4) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric==2.0.4) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric==2.0.4) (3.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric==2.0.4) (1.15.0)\r\n",
      "Building wheels for collected packages: torch-geometric\r\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=1995e0391364c639745f7fce866d5f32e15007d9577704d70438ee3e1fb138a1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/33/a3/07aa146f758cd91ebee36268011873ae31c2cfc59dec089e04\r\n",
      "Successfully built torch-geometric\r\n",
      "Installing collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.0.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: /kaggle/working/software/dependencies\r\n",
      "Obtaining file:///kaggle/working/software/graphnet\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/working/software/dependencies/awkward-1.8.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: colorlog>=6.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (6.7.0)\r\n",
      "Processing /kaggle/working/software/dependencies/ConfigUpdater-3.1.1-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.3.6)\r\n",
      "Requirement already satisfied: matplotlib>=3.5 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (3.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.21.6)\r\n",
      "Requirement already satisfied: pandas<2.0,>=1.3 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.3.5)\r\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (5.0.0)\r\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.8.2)\r\n",
      "Processing /kaggle/working/software/dependencies/ruamel.yaml-0.17.21-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit_learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.7.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.4.39)\r\n",
      "Processing /kaggle/working/software/dependencies/timer-0.2.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm>=4.64 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (4.64.0)\r\n",
      "Requirement already satisfied: wandb>=0.12 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.12.21)\r\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.11.0+cu115)\r\n",
      "Requirement already satisfied: torch-cluster>=1.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.6.0)\r\n",
      "Requirement already satisfied: torch-scatter>=2.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (2.0.9)\r\n",
      "Requirement already satisfied: torch-sparse>=0.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (0.6.13)\r\n",
      "Requirement already satisfied: torch-geometric>=2.0 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (2.0.4)\r\n",
      "Requirement already satisfied: pytorch-lightning<2.0,>=1.6 in /opt/conda/lib/python3.7/site-packages (from graphnet==0.2.4+328.g62eb86c8) (1.9.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from awkward<2.0,>=1.8->graphnet==0.2.4+328.g62eb86c8) (59.8.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (9.1.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (4.33.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (0.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (2.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (23.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.5->graphnet==0.2.4+328.g62eb86c8) (1.4.3)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.3->graphnet==0.2.4+328.g62eb86c8) (2022.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (4.1.1)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.11.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (6.0)\r\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (2023.1.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>=1.0->graphnet==0.2.4+328.g62eb86c8) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>=1.0->graphnet==0.2.4+328.g62eb86c8) (1.0.1)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (1.1.2)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (6.0.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.28.1)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (0.1.2)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (0.4.0)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.1.27)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (5.9.1)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.15.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (8.1.3)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (2.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.13.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.0.11)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (1.3.2)\r\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.20.3)\r\n",
      "Processing /kaggle/working/software/dependencies/ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (3.8.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (4.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=1.4->graphnet==0.2.4+328.g62eb86c8) (3.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2022.12.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->torch-geometric>=2.0->graphnet==0.2.4+328.g62eb86c8) (2.1.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (4.0.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.2.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.7.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (21.4.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (0.13.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (6.0.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0,>=1.6->graphnet==0.2.4+328.g62eb86c8) (1.3.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.12->graphnet==0.2.4+328.g62eb86c8) (3.0.5)\r\n",
      "Installing collected packages: timer, ruamel.yaml.clib, awkward, ruamel.yaml, configupdater, graphnet\r\n",
      "  Running setup.py develop for graphnet\r\n",
      "Successfully installed awkward-1.8.0 configupdater-3.1.1 graphnet-0.2.4+328.g62eb86c8 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 timer-0.2.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Move software to working disk\n",
    "!rm  -r software\n",
    "!scp -r /kaggle/input/graphnet-and-dependencies/software .\n",
    "\n",
    "# Install dependencies\n",
    "!pip install /kaggle/working/software/dependencies/torch-1.11.0+cu115-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/working/software/dependencies/torch_geometric-2.0.4.tar.gz\n",
    "\n",
    "!cd software/graphnet;pip install --no-index --find-links=\"/kaggle/working/software/dependencies\" -e .[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e09eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:22.327021Z",
     "iopub.status.busy": "2023-04-26T06:51:22.326666Z",
     "iopub.status.idle": "2023-04-26T06:51:22.397480Z",
     "shell.execute_reply": "2023-04-26T06:51:22.396251Z"
    },
    "papermill": {
     "duration": 0.082011,
     "end_time": "2023-04-26T06:51:22.400048",
     "exception": false,
     "start_time": "2023-04-26T06:51:22.318037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install GraphNeT\n",
    "import sys\n",
    "#sys.path.append('/kaggle/input/graphnet/graphnet/src')\n",
    "sys.path.append('/kaggle/working/software/graphnet/src')\n",
    "import graphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1a9866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:22.419066Z",
     "iopub.status.busy": "2023-04-26T06:51:22.418083Z",
     "iopub.status.idle": "2023-04-26T06:51:23.426295Z",
     "shell.execute_reply": "2023-04-26T06:51:23.425375Z"
    },
    "papermill": {
     "duration": 1.020876,
     "end_time": "2023-04-26T06:51:23.428430",
     "exception": false,
     "start_time": "2023-04-26T06:51:22.407554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyarrow \n",
    "\n",
    "DATA_PATH = '/kaggle/input/icecube-neutrinos-in-deep-ice/'\n",
    "SENSORS = DATA_PATH + 'sensor_geometry.csv'\n",
    "TRANSPERANCY = '/kaggle/input/icecube-additional/ice_transperancy.txt'\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/icecube-utils/')\n",
    "from prepare_sensors import prepare_sensors\n",
    "from ice_transparency import ice_transparency\n",
    "sensor_df = prepare_sensors(SENSORS)\n",
    "f_scattering, f_absorption = ice_transparency(TRANSPERANCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5b9905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:23.447193Z",
     "iopub.status.busy": "2023-04-26T06:51:23.445693Z",
     "iopub.status.idle": "2023-04-26T06:51:23.452362Z",
     "shell.execute_reply": "2023-04-26T06:51:23.451541Z"
    },
    "papermill": {
     "duration": 0.017131,
     "end_time": "2023-04-26T06:51:23.454442",
     "exception": false,
     "start_time": "2023-04-26T06:51:23.437311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "META_PATH = '/kaggle/input/batched-metadata/'\n",
    "def get_metadata_pd(batch, write=False):\n",
    "    if batch < 661:\n",
    "        return pd.read_parquet(META_PATH + f'train_meta_batches/batch_{batch}.parquet', \n",
    "                        engine=\"pyarrow\", use_threads=True)\n",
    "    elif batch == 661:\n",
    "        return pd.read_parquet(META_PATH + f'test_meta_batches/batch_{batch}.parquet', \n",
    "                        engine=\"pyarrow\", use_threads=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477610cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:23.470147Z",
     "iopub.status.busy": "2023-04-26T06:51:23.469883Z",
     "iopub.status.idle": "2023-04-26T06:51:27.436096Z",
     "shell.execute_reply": "2023-04-26T06:51:27.435126Z"
    },
    "papermill": {
     "duration": 3.976884,
     "end_time": "2023-04-26T06:51:27.438704",
     "exception": false,
     "start_time": "2023-04-26T06:51:23.461820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from graphnet.training.labels import Label\n",
    "\n",
    "class Direction(Label):\n",
    "    \"\"\"Class for producing my label.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Construct `MyCustomLabel`.\"\"\"\n",
    "        # Base class constructor\n",
    "        super().__init__(key=\"direction\")\n",
    "\n",
    "    def __call__(self, graph: Data) -> torch.tensor:\n",
    "        \"\"\"Compute label for `graph`.\"\"\"\n",
    "        zenith = graph.y[0]\n",
    "        azimuth = graph.y[1] # assuming y is a pandas dataframe\n",
    "               \n",
    "        dir_x = (torch.cos(azimuth) * torch.sin(zenith)).reshape(1)\n",
    "        dir_y = (torch.sin(azimuth) * torch.sin(zenith)).reshape(1)\n",
    "        dir_z = torch.cos(zenith).reshape(1)\n",
    "        direction = torch.cat([dir_x, dir_y, dir_z], dim=0)\n",
    "        return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42afbeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:27.455871Z",
     "iopub.status.busy": "2023-04-26T06:51:27.455285Z",
     "iopub.status.idle": "2023-04-26T06:51:27.565539Z",
     "shell.execute_reply": "2023-04-26T06:51:27.564655Z"
    },
    "papermill": {
     "duration": 0.121267,
     "end_time": "2023-04-26T06:51:27.567691",
     "exception": false,
     "start_time": "2023-04-26T06:51:27.446424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from typing import (\n",
    "    cast,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Union,\n",
    "    Iterable,\n",
    ")\n",
    "\n",
    "class IceCubeDataset(Dataset):\n",
    "    def __init__(self, event_ids, batch_id, PATH_TO_BATCH_FILES, \n",
    "                 f_scattering, f_absorption, sensor_df, y, x_features, y_features,\n",
    "                 pulse_limit=300, include_auxiliary=True, construct_graph=False,\n",
    "                 transform = None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "        self.event_ids = event_ids\n",
    "        self.batch_df = pd.read_parquet(PATH_TO_BATCH_FILES + f\"batch_{batch_id}.parquet\")\n",
    "        self.sensor_df = sensor_df\n",
    "        self.pulse_limit = pulse_limit\n",
    "        self.f_scattering = f_scattering\n",
    "        self.f_absorption = f_absorption\n",
    "        self.y = y\n",
    "        self.x_features = x_features\n",
    "        if include_auxiliary == False and 'auxiliary' in self.x_features:\n",
    "            self.x_features.remove('auxiliary')\n",
    "        self.include_auxiliary = include_auxiliary\n",
    "        self.y_features = y_features\n",
    "        self.construct_graph = construct_graph\n",
    "        self._label_fns = dict()\n",
    "        \n",
    "        \n",
    "        # weird scaling...really don't get any of the scaling stuff\n",
    "        self.batch_df[\"time\"] = (self.batch_df[\"time\"] - 1.0e04) / 3.0e4\n",
    "        self.batch_df[\"charge\"] = np.log10(self.batch_df[\"charge\"]) / 3.0\n",
    "        self.batch_df[\"auxiliary\"] = self.batch_df[\"auxiliary\"].astype(int) - 0.5\n",
    "       \n",
    "    def len(self):\n",
    "        return len(self.event_ids)\n",
    "    \n",
    "    def get_dir_vector(self, azimuth, zenith):\n",
    "        dir_x = np.cos(azimuth) * np.sin(zenith)\n",
    "        dir_y = np.sin(azimuth) * np.sin(zenith)\n",
    "        dir_z = np.cos(zenith)\n",
    "        directions = pd.Series({'direction_x':dir_x, 'direction_y':dir_y, 'direction_z':dir_z})\n",
    "        return directions\n",
    "    \n",
    "    def add_label(\n",
    "        self, fn: Callable[[Data], Any], key: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Add custom graph label define using function `fn`.\"\"\"\n",
    "        if isinstance(fn, Label):\n",
    "            key = fn.key\n",
    "        assert isinstance(\n",
    "            key, str\n",
    "        ), \"Please specify a key for the custom label to be added.\"\n",
    "        assert (\n",
    "            key not in self._label_fns\n",
    "        ), f\"A custom label {key} has already been defined.\"\n",
    "        self._label_fns[key] = fn\n",
    "\n",
    "    def get(self, idx):\n",
    "        event_id = self.event_ids[idx]\n",
    "        event = self.batch_df.loc[event_id]\n",
    "        event = pd.merge(event, self.sensor_df, on=\"sensor_id\")\n",
    "        if self.include_auxiliary == False:\n",
    "            event.drop(event[event.auxiliary == 0.5].index)\n",
    "        \n",
    "        x_feats = self.x_features.copy()\n",
    "        if 'scattering' in self.x_features:\n",
    "            x_feats.remove('scattering')\n",
    "        if 'absorption' in self.x_features:\n",
    "            x_feats.remove('absorption')\n",
    "        x = event[x_feats].values\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        data = Data(x=x, n_pulses=torch.tensor(x.shape[0], dtype=torch.int32), features=x_feats)\n",
    "\n",
    "        # Add ice transparency data\n",
    "        z = data.x[:, 2].numpy()\n",
    "        if 'scattering' in self.x_features:\n",
    "            scattering = torch.tensor(self.f_scattering(z), dtype=torch.float32).view(-1, 1)\n",
    "            data.x = torch.cat([data.x, scattering], dim=1)\n",
    "        if 'absorption' in self.x_features:\n",
    "            absorption = torch.tensor(self.f_absorption(z), dtype=torch.float32).view(-1, 1)\n",
    "            data.x = torch.cat([data.x, absorption], dim=1)\n",
    "\n",
    "        # Downsample the large events\n",
    "        if data.n_pulses > self.pulse_limit:\n",
    "            data.x = data.x[np.random.choice(data.n_pulses, self.pulse_limit)]\n",
    "            data.n_pulses = torch.tensor(self.pulse_limit, dtype=torch.int32)\n",
    "\n",
    "        # Builds graph from the k-nearest neighbours.\n",
    "        if self.construct_graph == True:\n",
    "            data.edge_index = knn_graph(\n",
    "                data.x[:, [0, 1, 2]],  # x, y, z\n",
    "                k=8,\n",
    "                batch=None,\n",
    "                loop=False\n",
    "            )\n",
    "        if self.y is not None:\n",
    "            y = self.y.loc[idx, :].values\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "            data.y = y\n",
    "            if self._label_fns:\n",
    "                for key in self._label_fns:\n",
    "                    data[key] = self._label_fns[key](data)\n",
    "            \n",
    "            '''\n",
    "            data.azimuth = self.y.loc[idx][self.y_features].azimuth\n",
    "            data.zenith = self.y.loc[idx][self.y_features].zenith\n",
    "            dirs = self.get_dir_vector(data.azimuth, data.zenith)\n",
    "            data.direction = torch.tensor(self.get_dir_vector(data.azimuth, data.zenith).values)\n",
    "            torch.reshape(data.direction, (1,3))\n",
    "            '''\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d250d263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:27.583668Z",
     "iopub.status.busy": "2023-04-26T06:51:27.583382Z",
     "iopub.status.idle": "2023-04-26T06:51:27.955488Z",
     "shell.execute_reply": "2023-04-26T06:51:27.954580Z"
    },
    "papermill": {
     "duration": 0.382955,
     "end_time": "2023-04-26T06:51:27.958138",
     "exception": false,
     "start_time": "2023-04-26T06:51:27.575183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction_x</th>\n",
       "      <th>direction_y</th>\n",
       "      <th>direction_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271161</td>\n",
       "      <td>-0.826088</td>\n",
       "      <td>-0.494015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913804</td>\n",
       "      <td>0.405607</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268879</td>\n",
       "      <td>0.618078</td>\n",
       "      <td>-0.738704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623491</td>\n",
       "      <td>-0.291423</td>\n",
       "      <td>0.725488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.490794</td>\n",
       "      <td>0.590501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   direction_x  direction_y  direction_z\n",
       "0     0.271161    -0.826088    -0.494015\n",
       "1     0.913804     0.405607     0.021108\n",
       "2     0.268879     0.618078    -0.738704\n",
       "3     0.623491    -0.291423     0.725488\n",
       "4     0.640648     0.490794     0.590501"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_ID = 1\n",
    "TRAIN_PATH = DATA_PATH + 'train/'\n",
    "batch_meta = get_metadata_pd(BATCH_ID, write=False)\n",
    "event_ids = list(batch_meta['event_id'])\n",
    "#x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering', 'absorption']\n",
    "#x_feats = ['x', 'y', 'z', 'time', \"charge\", \"auxiliary\"]\n",
    "x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering']\n",
    "y_feats = ['zenith', 'azimuth']\n",
    "y = batch_meta[y_feats].reset_index(drop=True)\n",
    "dir_x = np.cos(y.azimuth) * np.sin(y.zenith)\n",
    "dir_y = np.sin(y.azimuth) * np.sin(y.zenith)\n",
    "dir_z = np.cos(y.zenith)\n",
    "directions = pd.concat({'direction_x':dir_x, 'direction_y':dir_y, 'direction_z':dir_z}, axis = 1)\n",
    "directions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ed8db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:27.976607Z",
     "iopub.status.busy": "2023-04-26T06:51:27.976302Z",
     "iopub.status.idle": "2023-04-26T06:51:34.226628Z",
     "shell.execute_reply": "2023-04-26T06:51:34.225587Z"
    },
    "papermill": {
     "duration": 6.261419,
     "end_time": "2023-04-26T06:51:34.229114",
     "exception": false,
     "start_time": "2023-04-26T06:51:27.967695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = IceCubeDataset(event_ids, BATCH_ID, TRAIN_PATH, f_scattering, \n",
    "                         f_absorption, sensor_df, y, x_feats, y_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a521e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:34.245952Z",
     "iopub.status.busy": "2023-04-26T06:51:34.245659Z",
     "iopub.status.idle": "2023-04-26T06:51:34.253846Z",
     "shell.execute_reply": "2023-04-26T06:51:34.253153Z"
    },
    "papermill": {
     "duration": 0.018647,
     "end_time": "2023-04-26T06:51:34.255621",
     "exception": false,
     "start_time": "2023-04-26T06:51:34.236974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[32mINFO    \u001b[0m 2023-04-26 06:51:34 - Direction._configure_root_logger - Writing log to \u001b[1mlogs/graphnet_20230426-065134.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset.add_label(Direction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7afee6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:34.272637Z",
     "iopub.status.busy": "2023-04-26T06:51:34.271075Z",
     "iopub.status.idle": "2023-04-26T06:51:35.898425Z",
     "shell.execute_reply": "2023-04-26T06:51:35.897459Z"
    },
    "papermill": {
     "duration": 1.637591,
     "end_time": "2023-04-26T06:51:35.900569",
     "exception": false,
     "start_time": "2023-04-26T06:51:34.262978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2712, -0.8261, -0.4940])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get(0)['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96aedc8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:35.917627Z",
     "iopub.status.busy": "2023-04-26T06:51:35.917319Z",
     "iopub.status.idle": "2023-04-26T06:51:35.923488Z",
     "shell.execute_reply": "2023-04-26T06:51:35.922520Z"
    },
    "papermill": {
     "duration": 0.016704,
     "end_time": "2023-04-26T06:51:35.925522",
     "exception": false,
     "start_time": "2023-04-26T06:51:35.908818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = x_feats\n",
    "truth = y_feats\n",
    "\n",
    "config = {\n",
    "        #\"path\": '/kaggle/working/batch_1.db',\n",
    "        #\"inference_database_path\": '/kaggle/working/batch_51.db',\n",
    "        #\"pulsemap\": 'pulse_table',\n",
    "        #\"truth_table\": 'meta_table',\n",
    "        'neighbours': 8,\n",
    "        'graph_builder_columns' : [0, 1, 2], # x, y, z\n",
    "        'global_pooling_schemes' : [\"min\", \"max\", \"mean\"],\n",
    "        \"features\": features,\n",
    "        #\"truth\": truth,\n",
    "        \"index_column\": 'event_id',\n",
    "        #\"run_name_tag\": 'my_example',\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 2,\n",
    "        \"target\": 'direction',\n",
    "        \"early_stopping_patience\": 5,\n",
    "        \"fit\": {\n",
    "                \"max_epochs\": 10,\n",
    "                \"gpus\": [0],\n",
    "                \"distribution_strategy\": None,\n",
    "                },\n",
    "        #'train_selection': '/kaggle/working/train_selection_max_200_pulses.csv',\n",
    "        #'validate_selection': '/kaggle/working/validate_selection_max_200_pulses.csv',\n",
    "        #'test_selection': None,\n",
    "        #'base_dir': 'training'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd64e7f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:36.358471Z",
     "iopub.status.busy": "2023-04-26T06:51:36.358186Z",
     "iopub.status.idle": "2023-04-26T06:51:36.367104Z",
     "shell.execute_reply": "2023-04-26T06:51:36.366198Z"
    },
    "papermill": {
     "duration": 0.019315,
     "end_time": "2023-04-26T06:51:36.368943",
     "exception": false,
     "start_time": "2023-04-26T06:51:36.349628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Any, Optional, Union, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn.functional import (\n",
    "    one_hot,\n",
    "    cross_entropy,\n",
    "    binary_cross_entropy,\n",
    "    softplus,\n",
    ")\n",
    "\n",
    "from graphnet.utilities.config import save_model_config\n",
    "from graphnet.models.model import Model\n",
    "from graphnet.utilities.decorators import final\n",
    "\n",
    "# overriding graphnet VonMisesFischer3dLoss and parent LossFunction\n",
    "class vMF_Loss(Model):\n",
    "    \"\"\"Base class for loss functions in `graphnet`.\"\"\"\n",
    "\n",
    "    @save_model_config\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Construct `LossFunction`, saving model config.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @final\n",
    "    def forward(  # type: ignore[override]\n",
    "        self,\n",
    "        prediction: Tensor,\n",
    "        target: Tensor,\n",
    "        weights: Optional[Tensor] = None,\n",
    "        return_elements: bool = False,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        target = target.reshape(-1, 3)\n",
    "        \n",
    "        eps = 1e-8\n",
    "        kappa = prediction[:, 3]      \n",
    "        logC  = -kappa + torch.log( ( kappa+eps )/( 1-torch.exp(-2*kappa)+2*eps ) )\n",
    "        p = kappa.unsqueeze(1) * prediction[:, [0, 1, 2]]\n",
    "        return -( (target*p).sum(dim=1) + logC ).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1021526a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:36.385496Z",
     "iopub.status.busy": "2023-04-26T06:51:36.385230Z",
     "iopub.status.idle": "2023-04-26T06:51:36.546381Z",
     "shell.execute_reply": "2023-04-26T06:51:36.545464Z"
    },
    "papermill": {
     "duration": 0.17203,
     "end_time": "2023-04-26T06:51:36.548511",
     "exception": false,
     "start_time": "2023-04-26T06:51:36.376481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m [MainProcess] \u001b[33mWARNING \u001b[0m 2023-04-26 06:51:36 - warning - `icecube` not available. Some functionality may be missing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, List, Optional, Sequence, Tuple, Union, Dict\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.optim.adam import Adam\n",
    "#from graphnet.data.constants import FEATURES, TRUTH\n",
    "from graphnet.models.standard_model import StandardModel\n",
    "#from graphnet.models.detector.icecube import IceCubeKaggle\n",
    "from graphnet.models.gnn import DynEdge\n",
    "from graphnet.models.graph_builders import KNNGraphBuilder\n",
    "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa, ZenithReconstructionWithKappa, AzimuthReconstructionWithKappa\n",
    "from graphnet.training.callbacks import ProgressBar, PiecewiseLinearLR\n",
    "#from graphnet.training.loss_functions import VonMisesFisher3DLoss, VonMisesFisher2DLoss\n",
    "#from graphnet.training.labels import Direction\n",
    "from graphnet.training.utils import make_dataloader\n",
    "from graphnet.utilities.logging import Logger\n",
    "from pytorch_lightning import Trainer\n",
    "import pandas as pd\n",
    "from graphnet.models.detector.detector import Detector\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "#override graphnet class\n",
    "class IceCubeKaggle(Detector):\n",
    "    \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
    "\n",
    "    # Implementing abstract class attribute\n",
    "    features = features\n",
    "\n",
    "    def _forward(self, data: Data) -> Data:\n",
    "        \"\"\"Ingest data, build graph, and preprocess features.\n",
    "        Args:\n",
    "            data: Input graph data.\n",
    "        Returns:\n",
    "            Connected and preprocessed graph data.\n",
    "        \"\"\"\n",
    "        # Check(s) --- no we want to have flexible feature inputs\n",
    "        # Preprocessing was already done\n",
    "        data_features = [features[0] for features in data.features]\n",
    "        features = data_features\n",
    "\n",
    "        return data\n",
    "\n",
    "def build_model(config: Dict[str,Any], train_dataloader: Any) -> StandardModel:\n",
    "    \"\"\"Builds GNN from config\"\"\"\n",
    "    # Building model\n",
    "    detector = IceCubeKaggle(\n",
    "        graph_builder=KNNGraphBuilder(nb_nearest_neighbours=config['neighbours'], \n",
    "                                     columns=config['graph_builder_columns']),\n",
    "    )\n",
    "    detector.features = config['features']\n",
    "    gnn = DynEdge(\n",
    "        nb_inputs=detector.nb_outputs,\n",
    "        global_pooling_schemes=config['global_pooling_schemes'],\n",
    "    )\n",
    "\n",
    "   # if config[\"target\"] == 'direction':\n",
    "    task = DirectionReconstructionWithKappa(\n",
    "            hidden_size=gnn.nb_outputs,\n",
    "            target_labels=config[\"target\"],\n",
    "            #loss_function=VonMisesFisher3DLoss(),\n",
    "            loss_function = vMF_Loss(),\n",
    "        )\n",
    "    prediction_columns = [config[\"target\"] + \"_x\", \n",
    "                              config[\"target\"] + \"_y\", \n",
    "                              config[\"target\"] + \"_z\", \n",
    "                              config[\"target\"] + \"_kappa\" ]\n",
    "    additional_attributes = ['zenith', 'azimuth', 'event_id']\n",
    "\n",
    "    model = StandardModel(\n",
    "        detector=detector,\n",
    "        gnn=gnn,\n",
    "        tasks=[task],\n",
    "        optimizer_class=Adam,\n",
    "        optimizer_kwargs={\"lr\": 1e-03, \"eps\": 1e-03},\n",
    "        scheduler_class=PiecewiseLinearLR,\n",
    "        scheduler_kwargs={\n",
    "            \"milestones\": [\n",
    "                0,\n",
    "                len(train_dataloader) / 2,\n",
    "                len(train_dataloader) * config[\"fit\"][\"max_epochs\"],\n",
    "            ],\n",
    "            \"factors\": [1e-02, 1, 1e-02],\n",
    "        },\n",
    "        scheduler_config={\n",
    "            \"interval\": \"step\",\n",
    "        },\n",
    "    )\n",
    "    model.prediction_columns = prediction_columns\n",
    "    model.additional_attributes = additional_attributes\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9239e567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:36.565187Z",
     "iopub.status.busy": "2023-04-26T06:51:36.564918Z",
     "iopub.status.idle": "2023-04-26T06:51:36.572154Z",
     "shell.execute_reply": "2023-04-26T06:51:36.571115Z"
    },
    "papermill": {
     "duration": 0.018035,
     "end_time": "2023-04-26T06:51:36.574417",
     "exception": false,
     "start_time": "2023-04-26T06:51:36.556382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_step(config: Dict[str, Any], dataset_) -> StandardModel:\n",
    "    \"\"\"Builds and trains GNN according to config.\"\"\"\n",
    "    logger.info(f\"features: {config['features']}\")\n",
    "    logger.info(f\"truth: {config['target']}\")\n",
    "    \n",
    "    #archive = os.path.join(config['base_dir'], \"train_model_without_configs\")\n",
    "    #run_name = f\"dynedge_{config['target']}_{config['run_name_tag']}\"\n",
    "    \n",
    "    # do train-test split as:\n",
    "    train_len = int(0.7*dataset_.len())\n",
    "    train_loader = DataLoader(dataset_[:train_len], batch_size=config['batch_size'], shuffle=True, follow_batch=config['target']) # shuffle data every epoch\n",
    "    val_loader = DataLoader(dataset_[train_len:], batch_size=config['batch_size'], shuffle=False, follow_batch=config['target'])\n",
    "    \n",
    "    model = build_model(config, train_loader)\n",
    "\n",
    "    # Training model\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=config[\"early_stopping_patience\"],\n",
    "        ),\n",
    "        ProgressBar(),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        callbacks=callbacks,\n",
    "        **config[\"fit\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13324721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T06:51:36.590617Z",
     "iopub.status.busy": "2023-04-26T06:51:36.590331Z",
     "iopub.status.idle": "2023-04-26T06:51:36.888651Z",
     "shell.execute_reply": "2023-04-26T06:51:36.887417Z"
    },
    "papermill": {
     "duration": 0.308128,
     "end_time": "2023-04-26T06:51:36.890064",
     "exception": true,
     "start_time": "2023-04-26T06:51:36.581936",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "training_step() missing 1 required positional argument: 'dataset_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/2926864363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: training_step() missing 1 required positional argument: 'dataset_'"
     ]
    }
   ],
   "source": [
    "model = training_step(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8914a51",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-26T03:48:31.218023Z",
     "iopub.status.busy": "2023-04-26T03:48:31.216967Z",
     "iopub.status.idle": "2023-04-26T03:48:31.227571Z",
     "shell.execute_reply": "2023-04-26T03:48:31.226402Z",
     "shell.execute_reply.started": "2023-04-26T03:48:31.217969Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44f97c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset_for_batch(BATCH_ID):\n",
    "    TRAIN_PATH = DATA_PATH + 'train/'\n",
    "    batch_meta = get_metadata_for_batch(BATCH_ID, write=False)\n",
    "    event_ids = list(batch_meta['event_id'])\n",
    "    #x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering', 'absorption']\n",
    "    #x_feats = ['x', 'y', 'z', 'time', \"charge\", \"auxiliary\"]\n",
    "    x_feats = ['x', 'y', 'z', 'time', \"charge\", \"qe\", \"auxiliary\", 'scattering']\n",
    "    y_feats = ['zenith', 'azimuth']\n",
    "    y = batch_meta[y_feats].reset_index(drop=True)\n",
    "    return dataset\n",
    "\n",
    "inference_dataset = make_dataset_for_batch(2)\n",
    "# get first 10,000 samples only for batch 2 to do inference on\n",
    "inf_loader = DataLoader(inference_dataset[:10000], batch_size=config['batch_size'], shuffle=False)\n",
    "results = model.predict_as_dataframe(\n",
    "        gpus = [0],\n",
    "        dataloader = inf_loader,\n",
    "        prediction_columns=model.prediction_columns,\n",
    "        additional_attributes=model.additional_attributes,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 301.397385,
   "end_time": "2023-04-26T06:51:39.351272",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-26T06:46:37.953887",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
